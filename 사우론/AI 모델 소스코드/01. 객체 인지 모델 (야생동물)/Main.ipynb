{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8551ddbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import shutil\n",
    "import os \n",
    "import yaml\n",
    "import cv2\n",
    "from glob import glob\n",
    "from openpyxl import Workbook\n",
    "from scipy.sparse import data\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6788cc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# json 형태의 annotation 데이터를 YOLOv5 학습 형태에 맞게 txt 로 변환한다.\n",
    "\n",
    "classification = []\n",
    "count = []\n",
    "\n",
    "TOP = 0\n",
    "LEFT = 1\n",
    "BOTTOM = 2\n",
    "RIGHT = 3\n",
    "\n",
    "SQURE = 1\n",
    "\n",
    "class Label:\n",
    "\n",
    "\tdef __init__(self, fileName, imagePath):\n",
    "\t\tdata = self.parse_json_data(fileName)\n",
    "\t\tself.set_data(data, fileName, imagePath)\n",
    "\n",
    "\tdef parse_json_data(self, fileName):\n",
    "\t\twith open(fileName, encoding='utf-8-sig') as jsonFile:\n",
    "\t\t\tjsonData = json.load(jsonFile)\n",
    "\t\treturn jsonData\n",
    "\n",
    "\tdef set_data(self, data, fileName, imagePath):\n",
    "\t\tself.fileName = '.'.join(os.path.basename(fileName).split('.')[0:-1])\n",
    "\t\tself.width = int(data['images'][0]['width'])\n",
    "\t\tself.height = int(data['images'][0]['height'])\n",
    "\t\tself.annotations = data['annotations']\n",
    "\n",
    "\tdef get_bbox_point(self, bbox):\n",
    "\t\ttop = 10000\n",
    "\t\tleft = 10000\n",
    "\t\tbottom = -1\n",
    "\t\tright = -1\n",
    "\n",
    "\t\tfor i in bbox:\n",
    "\t\t\tif (i[0] < left): left = i[0]\n",
    "\t\t\tif (i[0] > right): right = i[0]\n",
    "\t\t\tif (i[1] < top): top = i[1]\n",
    "\t\t\tif (i[1] > bottom): bottom = i[1]\n",
    "\n",
    "\t\treturn ((top, left, bottom, right))\n",
    "\n",
    "\tdef get_segment_point(self, seg):\n",
    "\t\ttop = 10000\n",
    "\t\tleft = 10000\n",
    "\t\tbottom = -1\n",
    "\t\tright = -1\n",
    "\n",
    "\t\tfor i in range(len(seg)):\n",
    "\t\t\tif (i % 2 == 0):\n",
    "\t\t\t\tif (seg[i] < left): left = seg[i]\n",
    "\t\t\t\tif (seg[i] > right): right = seg[i]\n",
    "\t\t\telse:\n",
    "\t\t\t\tif (seg[i] < top): top = seg[i]\n",
    "\t\t\t\tif (seg[i] > bottom): bottom = seg[i]\n",
    "\n",
    "\t\treturn ((top, left, bottom, right))\n",
    "\n",
    "\tdef get_shape_point(self, shape):\n",
    "\t\tif (shape['bbox'] and len(shape['bbox']) != 0):\n",
    "\t\t\treturn self.get_bbox_point(shape['bbox'])\n",
    "\t\telif (shape['Segmentation'] and len(shape['Segmentation']) != 0):\n",
    "\t\t\treturn self.get_segment_point(shape['Segmentation'][0])\n",
    "\t\telse:\n",
    "\t\t\treturn (0, 0, 0, 0)\n",
    "\n",
    "\tdef point_to_txt(self, point):\n",
    "\t\tif (point[0]) not in classification:\n",
    "\t\t\tclassification.append(point[0])\n",
    "\t\t\tcount.append(0)\n",
    "\t\tidx = classification.index(point[0])\n",
    "\t\tcount[idx] += 1\n",
    "\n",
    "\t\tif (SQURE):\n",
    "\t\t\tr = (self.width - self.height) / 2\n",
    "\t\t\tw_center = ((point[1][LEFT] + point[1][RIGHT]) / 2) / self.width\n",
    "\t\t\th_center = (((point[1][TOP] + point[1][BOTTOM]) / 2) + r) / self.width\n",
    "\t\t\tw_len = (point[1][RIGHT] - point[1][LEFT]) / self.width\n",
    "\t\t\th_len = (point[1][BOTTOM] - point[1][TOP]) / self.width\n",
    "\t\telse:\n",
    "\t\t\tw_center = ((point[1][LEFT] + point[1][RIGHT]) / 2) / self.width\n",
    "\t\t\th_center = ((point[1][TOP] + point[1][BOTTOM]) / 2) / self.height\n",
    "\t\t\tw_len = (point[1][RIGHT] - point[1][LEFT]) / self.width\n",
    "\t\t\th_len = (point[1][BOTTOM] - point[1][TOP]) / self.height\n",
    "\t\treturn (idx, w_center, h_center, w_len, h_len)\n",
    "\n",
    "\tdef convert_data(self):\n",
    "\t\tself.points = []\n",
    "\t\tself.txt = []\n",
    "\t\tfor shape in self.annotations:\n",
    "\t\t\tself.points.append((shape['species'], self.get_shape_point(shape)))\n",
    "\t\tfor point in self.points:\n",
    "\t\t\tself.txt.append(self.point_to_txt(point))\n",
    "\n",
    "\tdef write_data(self, path):\n",
    "\t\twith open(path + self.fileName + \".txt\", 'w') as f:\n",
    "\t\t\tfor line in self.txt:\n",
    "\t\t\t\tf.write(' '.join(map(str, line)) + \"\\n\")\n",
    "\n",
    "def convert_data(file, targetPath, imagePath):\n",
    "\ttarget = Label(file, imagePath)\n",
    "\ttarget.convert_data()\n",
    "\ttarget.write_data(targetPath)\n",
    "\n",
    "json_count = [0]\n",
    "def convert(targetPath, src):\n",
    "\tdata_list = os.listdir(targetPath)\n",
    "\tfor line in data_list:\n",
    "\t\tif os.path.isdir(os.path.join(targetPath, line)):\n",
    "\t\t\tconvert(os.path.join(targetPath, line), src)\n",
    "\t\telif '.json' in line:\n",
    "\t\t\tjson_count[0] += 1\n",
    "\t\t\tprint(json_count[0], \"Data Convert:\", line, end='\\r')\n",
    "\t\t\tshutil.copyfile(targetPath + \"/\" + line, src + \"/json/\" + line)\n",
    "\t\t\tconvert_data(targetPath + \"/\" + line, src + \"/labels/\", src + \"/images/\")\n",
    "\t\telse:\n",
    "\t\t\tpass\n",
    "\n",
    "image_count = [0]\n",
    "def copy_image(targetPath, src):\n",
    "\tdata_list = os.listdir(targetPath)\n",
    "\tfor line in data_list:\n",
    "\t\tif os.path.isdir(os.path.join(targetPath, line)):\n",
    "\t\t\tcopy_image(os.path.join(targetPath, line), src)\n",
    "\t\telif '.jpg' in line:\n",
    "\t\t\timage_count[0] += 1\n",
    "\t\t\tprint(image_count[0], \"Image Copy:\", line, end='\\r')\n",
    "\t\t\tshutil.copyfile(targetPath + \"/\" + line, src + \"/images/\" + line)\n",
    "\t\telse:\n",
    "\t\t\tpass\n",
    "\n",
    "def write_yaml(target):\n",
    "\tdata = {}\n",
    "\tdata[\"names\"] = classification\n",
    "\tdata[\"nc\"] = len(classification)\n",
    "\tdata[\"train\"] = \"../Dataset/train.txt\"\n",
    "\tdata[\"val\"] = \"../Dataset/valid.txt\"\n",
    "\tdata[\"test\"] = \"../Dataset/test.txt\"\n",
    "\twith open(target, 'w', encoding='utf-8-sig') as f:\n",
    "\t\tyaml.dump(data, f, allow_unicode=True)\n",
    "\n",
    "def run_convert(targetPath, src, copy):\n",
    "\tif not os.path.isdir(src + \"/images\"):\n",
    "\t\tos.makedirs(src + \"/images/\")\n",
    "\tif not os.path.isdir(src + \"/labels\"):\n",
    "\t\tos.makedirs(src + \"/labels\")\n",
    "\tif not os.path.isdir(src + \"/json\"):\n",
    "\t\tos.makedirs(src + \"/json\")\n",
    "\tif copy:\n",
    "\t\tcopy_image(targetPath, src)\n",
    "\tconvert(targetPath, src)\n",
    "\twrite_yaml(os.path.join(src, \"data.yaml\"))\n",
    "\tfor i in range(len(classification)):\n",
    "\t\tprint(classification[i], \"is counted:\", count[i])\n",
    "\n",
    "run_convert(\"./OriginData\", \"./Dataset\", True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbda9b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변환된 데이터셋에 있는 이미지를 학습에 맞게 정사각형으로 변환 및 416x416 사이즈로 변경한다.\n",
    "\n",
    "IMG_SIZE = 416\n",
    "\n",
    "def image_resize(target):\n",
    "\timg = cv2.imread(target)\n",
    "\th, w = img.shape[:2]\n",
    "\n",
    "\tcolor = 0\n",
    "\tif w > h:\n",
    "\t\tborderSize = int((w - h) / 2)\n",
    "\t\tborder = cv2.copyMakeBorder(\n",
    "\t\t\timg,\n",
    "\t\t\ttop=borderSize,\n",
    "\t\t\tbottom=borderSize,\n",
    "\t\t\tleft=0,\n",
    "\t\t\tright=0,\n",
    "\t\t\tborderType=cv2.BORDER_CONSTANT,\n",
    "\t\t\tvalue=[color, color, color]\n",
    "\t\t)\n",
    "\telse:\n",
    "\t\tborderSize = int((h - w) / 2)\n",
    "\t\tborder = cv2.copyMakeBorder(\n",
    "\t\t\timg,\n",
    "\t\t\ttop=0,\n",
    "\t\t\tbottom=0,\n",
    "\t\t\tleft=borderSize,\n",
    "\t\t\tright=borderSize,\n",
    "\t\t\tborderType=cv2.BORDER_CONSTANT,\n",
    "\t\t\tvalue=[color, color, color]\n",
    "\t\t)\n",
    "\n",
    "\tresize = cv2.resize(border, (IMG_SIZE, IMG_SIZE), interpolation = cv2.INTER_CUBIC)\n",
    "\tcv2.imwrite(target, resize)\n",
    "\n",
    "def resizing_img(targetPath):\n",
    "\tcount = 0\n",
    "\timgList = glob(targetPath + '/*.jpg')\n",
    "\tfor img in imgList:\n",
    "\t\tcount+=1\n",
    "\t\tprint(count, \"image resizing :\", img)\n",
    "\t\timage_resize(img)\n",
    "\n",
    "resizing_img(\"./Dataset/images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a7badb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습에 사용할 데이터셋을 Train:Valid:Test 로 구분하여 각 8:1:1 의 비율로 나눈다.\n",
    "# 나눠진 데이터셋의 상세 내용은 count.xlsx 엑셀파일에 저장\n",
    "# 에러가 있는 데이터는 err.txt 에 저장\n",
    "\n",
    "pr = [0]\n",
    "\n",
    "animal = [\"고라니\", \"멧돼지\", \"너구리 \", \"다람쥐\", \"청설모\", \"반달가슴곰\", \"족제비\", \"멧토끼\", \"왜가리\", \"중대백로\", \"노루\"]\n",
    "obj_count = []\n",
    "img_count = []\n",
    "err_count = []\n",
    "\n",
    "def get_json_data(fileName, trainList, validList, testList):\n",
    "\n",
    "\twith open(fileName, encoding='utf-8-sig') as jsonFile:\n",
    "\t\tjsonData = json.load(jsonFile)\n",
    "\tfName = ('.'.join(fileName.split('.')[0:-1]) + \".jpg\").replace(\"/json/\", \"/images/\")\n",
    "\tpr[0] += 1\n",
    "\tprint(pr, fName)\n",
    "\n",
    "\tday = str(jsonData['images'][0]['type'])\n",
    "\tif day != \"RGB\" and day != \"IR\":\n",
    "\t\terr_count.append(fName)\n",
    "\t\treturn\n",
    "\n",
    "\tobj_list = jsonData['annotations']\n",
    "\n",
    "\ttrainCount = 0\n",
    "\tvalidCount = 0\n",
    "\ttestCount = 0\n",
    "\n",
    "\tfor i in obj_count:\n",
    "\t\tif i[0] == (\"train\", obj_list[0]['species'], day):\ttrainCount += i[1]\n",
    "\t\telif i[0] == (\"valid\", obj_list[0]['species'], day):\tvalidCount += i[1]\n",
    "\t\telif i[0] == (\"test\", obj_list[0]['species'], day):\ttestCount += i[1]\n",
    "\n",
    "\tif int(trainCount / 8) < validCount:\n",
    "\t\tdata_type = \"train\"\n",
    "\t\ttrainList.append(fName)\n",
    "\telif validCount <= testCount:\n",
    "\t\tdata_type = \"valid\"\n",
    "\t\tvalidList.append(fName)\n",
    "\telse:\n",
    "\t\tdata_type = \"test\"\n",
    "\t\ttestList.append(fName)\n",
    "\n",
    "\tfor obj in obj_list:\n",
    "\t\tcheck = 0\n",
    "\t\tfor i in obj_count:\n",
    "\t\t\tif i[0] == (data_type, obj['species'], day):\n",
    "\t\t\t\ti[1] += 1\n",
    "\t\t\t\tcheck = 1\n",
    "\t\t\t\tbreak\n",
    "\t\tif not check:\n",
    "\t\t\tobj_count.append([(data_type, obj['species'], day), 1])\n",
    "\n",
    "\tspec = animal[int(os.path.basename(fileName).split('_')[0][1:]) - 1]\n",
    "\tcheck = 0\n",
    "\tfor j in img_count:\n",
    "\t\tif j[0] == (data_type, spec, day):\n",
    "\t\t\tj[1] += 1\n",
    "\t\t\tcheck = 1\n",
    "\t\t\tbreak\n",
    "\tif not check:\n",
    "\t\timg_count.append([(data_type, spec, day), 1])\n",
    "\n",
    "def parse_data(targetPath, trainList, validList, testList):\n",
    "\tdata_list = os.listdir(targetPath)\n",
    "\tfor line in data_list:\n",
    "\t\tif os.path.isdir(os.path.join(targetPath, line)):\n",
    "\t\t\tparse_data(os.path.join(targetPath, line), trainList, validList, testList)\n",
    "\t\telif '.json' in line:\n",
    "\t\t\tget_json_data(targetPath + \"/\" + line, trainList, validList, testList)\n",
    "\t\telse:\n",
    "\t\t\tpass\n",
    "\n",
    "def print_data(writePath):\n",
    "\tobj_count.sort()\n",
    "\timg_count.sort()\n",
    "\n",
    "\tcount = 0\n",
    "\tprint(\"==========object count==========\")\n",
    "\tfor i in obj_count:\n",
    "\t\tprint(f\"{i[0][0]}: {i[0][1]}: {i[0][2]}: {i[1]} counted\")\n",
    "\t\tcount += i[1]\n",
    "\tprint(\"count:\",count)\n",
    "\n",
    "\tcount = 0\n",
    "\tprint(\"==========image count==========\")\n",
    "\tfor i in img_count:\n",
    "\t\tprint(f\"{i[0][0]}: {i[0][1]}: {i[0][2]}: {i[1]} counted\")\n",
    "\t\tcount += i[1]\n",
    "\tprint(\"count:\",count)\n",
    "\n",
    "\tprint(\"==========err count==========\")\n",
    "\twith open(writePath + \"/err.txt\", \"w\", encoding='utf-8-sig') as f:\n",
    "\t\tf.write(\"\\n\".join(err_count) + \"\\n\")\n",
    "\tprint(\"count:\",len(err_count))\n",
    "\n",
    "def print_excel(writePath):\n",
    "\twb = Workbook()\n",
    "\tws = wb.active\n",
    "\tws.title = \"count\"\n",
    "\tws.append([\"Object\"])\n",
    "\tws.append([\"data_type\", \"object_type\", \"day\", \"count\"])\n",
    "\tfor i in obj_count:\n",
    "\t\tws.append(i[0] + (i[1],))\n",
    "\n",
    "\tws.append([\"Image\"])\n",
    "\tws.append([\"data_type\", \"object_type\", \"day\", \"count\"])\n",
    "\tfor i in img_count:\n",
    "\t\tws.append(i[0] + (i[1],))\n",
    "\twb.save(writePath + \"/count.xlsx\")\n",
    "\n",
    "def split_dataset(targetPath, writePath):\n",
    "\n",
    "\ttargetPath = os.path.abspath(targetPath)\n",
    "\ttrain_list = []\n",
    "\tvalid_list = []\n",
    "\ttest_list = []\n",
    "\tparse_data(targetPath, train_list, valid_list, test_list)\n",
    "    \n",
    "\twith open(writePath + \"/train.txt\", \"w\", encoding='utf-8-sig') as f:\n",
    "\t\tf.write(\"\\n\".join(train_list) + \"\\n\")\n",
    "\twith open(writePath + \"/valid.txt\", \"w\", encoding='utf-8-sig') as f:\n",
    "\t\tf.write(\"\\n\".join(valid_list) + \"\\n\")\n",
    "\twith open(writePath + \"/test.txt\", \"w\", encoding='utf-8-sig') as f:\n",
    "\t\tf.write(\"\\n\".join(test_list) + \"\\n\")\n",
    "\n",
    "\tprint(\"train data: \", len(train_list))\n",
    "\tprint(\"valid data: \", len(valid_list))\n",
    "\tprint(\"test data: \", len(test_list))\n",
    "\tprint_data(writePath)\n",
    "\tprint_excel(writePath)\n",
    "\n",
    "\treturn test_list\n",
    "\n",
    "split_dataset(\"./Dataset/json\", \"./Dataset\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acdcaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# yolo 및 yolo 실행에 필요한 모듈 설치\n",
    "!git clone https://github.com/ultralytics/yolov5.git\n",
    "\n",
    "%cd yolov5\n",
    "!pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2019265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# yolo 학습 코드 (약 120시간 실행) \n",
    "\n",
    "!sudo python3 train.py --img 416 --batch 64 --epochs 100 --data ../Dataset/data.yaml --cfg ./models/yolov5s.yaml --weights yolov5s.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9672f4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# yolo 테스트 코드\n",
    "\n",
    "!sudo python3 val.py --data ../Dataset/data.yaml --batch 128 --weights ./runs/train/exp/weights/best.pt --task test --img 416 --save-txt --save-conf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
